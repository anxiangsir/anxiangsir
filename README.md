## About Me
![visitors](https://visitor-badge.laobi.icu/badge?page_id=anxiangsir.anxiangsir)
[![](https://img.shields.io/github/stars/anxiangsir?color=fefb7b&logo=Undertale)](https://github-readme-stats.vercel.app/api?username=anxiangsir&hide_title=false&hide_border=true&show_icons=true&include_all_commits=true&line_height=20&bg_color=0,EC6C6C,FFD479,FFFC79,73FA79&theme=graywhite&locale=cn)
[![](https://img.shields.io/github/followers/anxiangsir?color=27da6b&logo=Handshake)](https://github.com/anxiangsir?tab=followers)
<p align="left">
<br>
<samp>
Hello there! I'm <b><a rel="nofollow noopener noreferrer" target="_blank" href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=zh-CN">Xiang An</a></b>.
<br>I'm a Computer Engineering.<br>  
</samp>
<img src="https://raw.githubusercontent.com/TanZng/TanZng/master/assets/hollor_knight3.gif" width="200" alt=""/>
</p>

## &#x1f4c8; GitHub Stats

<p href="https://github.com/deepinsight/insightface">
  <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=deepinsight&repo=insightface&title_color=ffffff&text_color=c9cacc&icon_color=2bbc8a&bg_color=1d1f21" />
</p>
<p href="https://github.com/anxiangsir/urban_seg">
  <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=anxiangsir&repo=urban_seg&title_color=ffffff&text_color=c9cacc&icon_color=2bbc8a&bg_color=1d1f21" />
</p>  
<p href="https://github.com/deepglint/unicom">
  <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=deepglint&repo=unicom&title_color=ffffff&text_color=c9cacc&icon_color=2bbc8a&bg_color=1d1f21" />
</p>  



## &#x270d; Paper & Writing

###### Welcome to discuss our latest work.

- Vision RWKV Pretrain:  
[RWKV-CLIP: A Robust Vision-Language Representation Learner](https://github.com/deepglint/RWKV-CLIP/tree/main)

![fig](https://github.com/deepglint/RWKV-CLIP/blob/main/figure/RWKV_architecture_00.png)

- Personalized Face Generation:  
[IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models](https://arxiv.org/html/2403.13535v2)


![fig](https://github.com/anxiangsir/anxiangsir/assets/31175974/9e2a76ed-8f3e-44f0-8423-7b5618d2ab47)

- Large-scale Vision Model Trained on **LAION400M** with Weak Supervision:  
[UNICOM: Universal and Compact Representation Learning for Image Retrieval](https://arxiv.org/pdf/2304.05884) in **ICLR2023**    
![fig](https://github.com/anxiangsir/insightface_arcface_log/blob/master/unicom.png)  


- **Distributed and Hybrid Parallel Large-Scale Classification** Algorithm:  
[Partial FC:Efficient and Robust Training of Face Recognition CNNs by Partial FC](https://openaccess.thecvf.com/content/CVPR2022/papers/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.pdf) in **CVPR2023**    

![fig](https://github.com/anxiangsir/insightface_arcface_log/blob/master/pfc.png)

<!--
![](http://profile-counter.glitch.me/anxiangsir/count.svg)
**anxiangsir/anxiangsir** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
