

<p align="left">
  <a href="https://anxiangsir.github.io/"><img src="https://img.shields.io/badge/ðŸŒ_Portfolio-Visit_Website-6366F1?style=for-the-badge" alt="Website"></a>
  <a href="https://scholar.google.com.hk/citations?user=1ckaPgwAAAAJ&hl=en"><img src="https://img.shields.io/badge/ðŸ“š_Google_Scholar-Citations-4285F4?style=for-the-badge" alt="Google Scholar"></a>
</p>


<!---

### ðŸš€ Selected Research

> *Building democratized, efficient, and large-scale vision systems.*

| Year | Conference | Project / Paper |
| :--- | :--- | :--- |
| **2025** | <img src="https://img.shields.io/badge/Coming_Soon-ICCV-blue?style=flat-square"> | **[RICE: Region-based Cluster Discrimination](https://github.com/deepglint/MVT)** <br> *Boosting OCR & localization for ViTs* |
| **2025** | <img src="https://img.shields.io/badge/Open_Source-SOTA-green?style=flat-square"> | **[LLaVA-OneVision-1.5](https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5)** <br> *Fully Open Framework for Democratized Multimodal Training* |
| **2024** | <img src="https://img.shields.io/badge/ECCV-2024-red?style=flat-square"> | **[MLCD](https://github.com/deepglint/unicom)** <br> *Multi-label Cluster Discrimination on LAION-400M* |
| **2023** | <img src="https://img.shields.io/badge/ICLR-2023-orange?style=flat-square"> | **[UNICOM](https://arxiv.org/pdf/2304.05884)** <br> *Universal and Compact Representation Learning* |
| **2022** | <img src="https://img.shields.io/badge/CVPR-2022-blueviolet?style=flat-square"> | **[Partial FC](https://github.com/deepinsight/insightface)** <br> *Training 10 Million Identities on a Single Machine* |

<br>

--->

![](https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=anxiangsir&theme=2077&count_private=true&include_all_commits=true)


---

**We are hiring!**  
If you are passionate about **Vision Pretraining** & **LMMs**, drop me an email at `anxiangsir@outlook.com` ðŸ“©

![visitors](https://visitor-badge.laobi.icu/badge?page_id=anxiangsir.anxiangsir)
